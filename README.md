# llm_finetuning
experimenting with llama3 

Finetuned Unsloth's 4 bit quantized Llama 3 8B using SFT , and trained model using DPO on [Dataset](https://huggingface.co/datasets/argilla/distilabel-math-preference-dpo)

